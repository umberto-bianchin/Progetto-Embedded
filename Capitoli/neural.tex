\bchapter{Storia delle Neural Newtorks}

Le origini concettuali delle reti neurali affondano le loro radici in discipline diverse, che includono la neuroscienza, la matematica e l'informatica.
Gli anni '40 del XX secolo segnano l'inizio del percorso storico delle reti neurali, con i lavori di Warren McCulloch e Walter Pitts. Questi scienziati
svilupparono i primi modelli concettuali di neuroni artificiali, ispirati alla struttura e al funzionamento dei neuroni biologici presenti nel cervello
umano. Il loro lavoro culminò con la pubblicazione nel 1943 di "A Logical Calculus of the Ideas Immanent in Nervous Activity", un articolo che presentava
un modello matematico semplificato di neurone.
Nel 1949, Donald Hebb formulò la sua famosa regola di apprendimento, un principio fondamentale nel funzionamento delle ANN. La regola di Hebb afferma che
la forza della connessione tra due neuroni aumenta quando entrambi sono attivi contemporaneamente. Questo principio di plasticità sinaptica, che riflette
il modo in cui il cervello apprende e si adatta, è alla base della capacità delle ANN di apprendere dai dati.
Tuttavia, fu negli anni '50 che il concetto di rete neurale artificiale iniziò a prendere forma concreta grazie al lavoro di Frank Rosenblatt, che nel
1957 sviluppò il perceptron, un modello di rete neurale che poteva imparare dai dati e compiere operazioni di riconoscimento visivo. Questo lavoro aprì
la strada allo studio delle reti neurali artificiali e generò un grande entusiasmo riguardo alle loro potenziali applicazioni.

Nel decennio successivo, le reti neurali continuarono a evolversi grazie alle ricerche di scienziati come Marvin Minsky e Seymour Papert, che svilupparono
nuove tecniche di addestramento e compresero meglio i limiti del perceptron. Di contro, durante gli anni '70 e '80, il campo attraversò un periodo di
relativo disinteresse, noto come "inverno neurale", a causa delle limitazioni del perceptron.
Con l'avvento di nuove tecniche di apprendimento e la disponibilità di maggiore potenza di calcolo, il campo delle reti neurali conobbe una rinascita.
Geoffrey Hinton, Yoshua Bengio e Yann LeCun furono tra i principali protagonisti di questa rinascita, sviluppando algoritmi più efficaci e metodi di
addestramento migliori per le reti neurali.

L'avvento dell'era digitale e l'enorme aumento della disponibilità di dati hanno ulteriormente alimentato il progresso delle reti neurali. Oggi, le reti
neurali sono all'avanguardia dell'intelligenza artificiale e vengono utilizzate in una vasta gamma di applicazioni, tra cui l'elaborazione del linguaggio
naturale, il riconoscimento di immagini, la guida autonoma e molto altro ancora. 
In particolare, lato mobile, l’avvento delle reti neurali è stato sostenuto sia lato hardware che lato software.
Nel 2017, Huawei, società già ampiamente affermata sul mercato mobile, ha presentato il primo smartphone con hardware NPU integrato, il Huawei Mate 10 pro,
avente il chip kirin 970 di ultima generazione. Grazie a questa nuova integrazione hardware, i competitors principali iniziarono a lavorare lato Neural
Networks, aumentando di fatto le possibilità mobile e integrando nuovi dispositivi NPU in molti dei nuovi dispositivi ora sul mercato.
Lato software, la fama delle reti neurali ha spinto allo sviluppo di API e Framework per le reti neurali. Android, infatti, ha implementato a partire da
Android 8.1 API dedicate, che operano a basso livello, per la gestione di dispositivi di calcolo.
Framework come PyTorch Mobile e TensorFlow Lite sono nati per semplificare l’utilizzo di queste API e poterle sfruttare a pieno.
